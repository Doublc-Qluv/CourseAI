{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NiN\n",
    "\n",
    "- 全连接的问题\n",
    "- -卷积层需要较少的参数$c_i \\times c_o \\times k^2$\n",
    "- 但卷积层后的第一个全连接层的参数\n",
    "  - LeNet   16x5x5x120=48k\n",
    "  - AlexNet 256x5x5x4096=26M\n",
    "  - VGG  512x7x7x4096=102M\n",
    "\n",
    "## NiN块\n",
    "- 一个卷积层后跟两个全连接层\n",
    "  - 步幅1，无填充，输出形状跟卷积层输出一样\n",
    "  - 起到全连接层的作用\n",
    "\n",
    "## NiN架构\n",
    "- 无全连接层\n",
    "- 交替使用NiN块和步幅为2的最大池化层\n",
    "  - 逐步减少高宽和增大通道数\n",
    "- 最后使用全局平均池化层得到输出\n",
    "  - 其输入通道数是类别数\n",
    "\n",
    "## 总结\n",
    "- NiN块使用卷积层加两个$1\\times 1$卷积层，\n",
    "  - 后者对每个像素增加了非线性性\n",
    "- NiN使用全局平局池化层来代替VGG和AlexNet中的全连接层\n",
    "  - 不容易过拟合，更少的参数个数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import d2l_source.d2l as d2l\n",
    "\n",
    "# NiN块\n",
    "def nin_block(in_channels, out_channels, kernel_size, strides, padding):\n",
    "    return nn.Sequential(\n",
    "        nn.Conv2d(in_channels, out_channels, kernel_size, strides, padding),\n",
    "        nn.ReLU(),\n",
    "        nn.Conv2d(out_channels, out_channels, kernel_size=1), nn.ReLU(),\n",
    "        nn.Conv2d(out_channels, out_channels, kernel_size=1), nn.ReLU())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NiN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = nn.Sequential(\n",
    "    nin_block(1, 96, kernel_size=11, strides=4, padding=0),\n",
    "    nn.MaxPool2d(3, stride=2),\n",
    "    nin_block(96, 256, kernel_size=5, strides=1, padding=2),\n",
    "    nn.MaxPool2d(3, stride=2),\n",
    "    nin_block(256, 384, kernel_size=3, strides=1, padding=1),\n",
    "    nn.MaxPool2d(3, stride=2),\n",
    "    nn.Dropout(0.5),\n",
    "    # 标签类别数是10\n",
    "    nin_block(384, 10, kernel_size=3, strides=1, padding=1),\n",
    "    nn.AdaptiveAvgPool2d((1, 1)),\n",
    "    # 将四维的输出转成二维的输出，其形状为(批量大小,10)\n",
    "    nn.Flatten())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "查看每个块的输出形状"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = torch.rand(size=(1, 1, 224, 224))\n",
    "for layer in net:\n",
    "    X = layer(X)\n",
    "    print(layer.__class__.__name__,'output shape:\\t', X.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr, num_epochs, batch_size = 0.1, 10, 128\n",
    "train_iter, test_iter = d2l.load_data_fashion_mnist(batch_size, resize=224)\n",
    "d2l.train_ch6(net, train_iter, test_iter, num_epochs, lr, d2l.try_gpu())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.9 (main, Jan 11 2023, 15:21:40) [GCC 11.2.0]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c44678fd19ad019ded79369569e5d8df0528d61f5c93a61b5bcbc1a4ac615169"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
